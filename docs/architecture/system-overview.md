# Bifrost System Architecture

Bifrost is a **high-performance**, **horizontally scalable** middleware that acts as a unified gateway to multiple AI model providers. Optimized to handle **10,000+ requests per second (RPS)** through sophisticated concurrency management, memory optimization, and connection pooling.

## ğŸ¯ Architecture Principles

| Principle                      | Description                                  | Benefit                              |
| ------------------------------ | -------------------------------------------- | ------------------------------------ |
| **ğŸ”„ Asynchronous Processing** | Channel-based worker pools per provider      | High concurrency, no blocking        |
| **ğŸ’¾ Memory Pool Management**  | Object pooling minimizes GC pressure         | Sustained high throughput            |
| **ğŸ—ï¸ Provider Isolation**      | Dedicated workers and resources per provider | Fault tolerance, independent scaling |
| **ğŸ”Œ Plugin-First Design**     | Extensible middleware without core changes   | Custom business logic injection      |
| **âš¡ Connection Optimization** | HTTP/2, keep-alive, connection pooling       | Reduced latency, higher efficiency   |

---

## ğŸ—ï¸ High-Level Architecture

```mermaid
graph TB
    subgraph "Client Layer"
        HTTP[HTTP Transport]
        SDK[Go SDK]
        gRPC[gRPC Transport]
    end

    subgraph "Bifrost Core"
        LB[Load Balancer/Router]
        PM[MCP Manager]
        subgraph "Request Processing"
            PP[Plugin Pipeline]
            RQ[Request Queue Manager]
            WP[Worker Pool Manager]
        end
        subgraph "Memory Management"
            CP[Channel Pool]
            RP[Response Pool]
            MP[Message Pool]
        end
    end

    subgraph "Provider Layer"
        subgraph "OpenAI Workers"
            OW1[Worker 1]
            OW2[Worker 2]
            OWN[Worker N]
        end
        subgraph "Anthropic Workers"
            AW1[Worker 1]
            AW2[Worker 2]
            AWN[Worker N]
        end
        subgraph "Other Providers"
            PW1[Bedrock Workers]
            PW2[Azure Workers]
            PWN[Other Workers]
        end
    end

    subgraph "External Systems"
        OPENAI[OpenAI API]
        ANTHROPIC[Anthropic API]
        BEDROCK[Amazon Bedrock]
        AZURE[Azure OpenAI]
        MCP[MCP Servers]
    end

    HTTP --> LB
    SDK --> LB
    gRPC --> LB
    LB --> PM
    PM --> PP
    PP --> RQ
    RQ --> WP
    WP --> CP
    WP --> RP
    WP --> MP

    WP --> OW1
    WP --> AW1
    WP --> PW1

    OW1 --> OPENAI
    OW2 --> OPENAI
    OWN --> OPENAI

    AW1 --> ANTHROPIC
    AW2 --> ANTHROPIC
    AWN --> ANTHROPIC

    PW1 --> BEDROCK
    PW2 --> AZURE

    PM --> MCP
```

**Key Components:**

- **ğŸ”— Transport Layer**: HTTP REST API, Go SDK, future gRPC
- **ğŸ£ Plugin Pipeline**: Pre/post-hooks for custom logic
- **ğŸ’¾ Memory Pools**: Object reuse for zero-allocation processing
- **âš™ï¸ Worker Pools**: Provider-specific concurrent processors
- **ğŸ”‘ Key Management**: Weighted API key distribution
- **ğŸ› ï¸ MCP Integration**: External tool discovery and execution

---

## ğŸ”„ Request Processing Flow

```mermaid
sequenceDiagram
    participant Client
    participant Transport
    participant Bifrost
    participant Plugin
    participant Provider
    participant AIService

    Client->>Transport: HTTP/SDK Request
    Transport->>Bifrost: BifrostRequest
    Bifrost->>Plugin: PreHook()
    Plugin-->>Bifrost: Modified Request

    Bifrost->>Bifrost: Get Channel from Pool
    Bifrost->>Bifrost: Select API Key (Weighted)
    Bifrost->>Provider: Queue Request

    Provider->>Provider: Worker Picks Up Request
    Provider->>AIService: HTTP Request
    AIService-->>Provider: HTTP Response

    Provider->>Bifrost: Response/Error
    Bifrost->>Plugin: PostHook()
    Plugin-->>Bifrost: Modified Response

    Bifrost->>Bifrost: Return Channel to Pool
    Bifrost-->>Transport: BifrostResponse
    Transport-->>Client: HTTP/SDK Response
```

**Processing Stages:**

1. **ğŸšª Transport Layer**: HTTP â†’ `schemas.BifrostRequest`
2. **ğŸ£ Plugin PreHooks**: Request modification, auth, rate limiting
3. **ğŸ’¾ Memory Pool**: Get reusable channel object
4. **ğŸ”‘ Key Selection**: Weighted random API key selection
5. **âš™ï¸ Worker Queue**: Provider-specific request queuing
6. **ğŸŒ HTTP Call**: Actual AI provider API request
7. **ğŸ£ Plugin PostHooks**: Response modification, caching, logging
8. **â™»ï¸ Pool Return**: Release channel object for reuse

---

## âš™ï¸ Core Components

### Memory Management

From `/core/schemas/bifrost.go`:

```go
type BifrostConfig struct {
    Account            Account           `json:"account"`
    Plugins            []Plugin          `json:"plugins,omitempty"`
    InitialPoolSize    int              `json:"initial_pool_size,omitempty"`    // Default: 100
    DropExcessRequests bool             `json:"drop_excess_requests,omitempty"` // Default: false
    MCPConfig          *MCPConfig       `json:"mcp_config,omitempty"`
    Logger             Logger           `json:"logger,omitempty"`
}
```

**Pool Configuration Guidelines:**

- `InitialPoolSize: 100` - Standard (< 1k RPS)
- `InitialPoolSize: 1000` - High throughput (1k-5k RPS)
- `InitialPoolSize: 20000` - Ultra high throughput (10k+ RPS)

### Provider Worker Pools

From `/core/schemas/provider.go`:

```go
type ProviderConfig struct {
    NetworkConfig            NetworkConfig            `json:"network_config,omitempty"`
    ConcurrencyAndBufferSize ConcurrencyAndBufferSize `json:"concurrency_and_buffer_size,omitempty"`
    ProxyConfig              *ProxyConfig             `json:"proxy_config,omitempty"`
    MetaConfig               interface{}              `json:"meta_config,omitempty"`
    Logger                   Logger                   `json:"logger,omitempty"`
}

type ConcurrencyAndBufferSize struct {
    Concurrency int `json:"concurrency,omitempty"` // Default: 10
    BufferSize  int `json:"buffer_size,omitempty"` // Default: 100
}
```

### API Key Management

From `/core/schemas/account.go`:

```go
type Key struct {
    Value  string   `json:"value"`  // The actual API key value
    Models []string `json:"models"` // List of models this key can access
    Weight float64  `json:"weight"` // Weight for load balancing (0.0-1.0)
}
```

---

## ğŸ“Š Performance Characteristics

### Benchmark Results (5000 RPS Test)

| Instance Type | Success Rate | Avg Latency | Peak Memory | Bifrost Overhead |
| ------------- | ------------ | ----------- | ----------- | ---------------- |
| t3.medium     | 100.00%      | 2.12s       | 1312.79 MB  | **59 Âµs**        |
| t3.xlarge     | 100.00%      | 1.61s       | 3340.44 MB  | **11 Âµs**        |

**Key Performance Metrics:**

- **ğŸ“Š Queue Wait Time**: 1.67 Âµs (t3.xlarge)
- **ğŸ”‘ Key Selection**: 10 ns (t3.xlarge)
- **ğŸ“‹ Message Formatting**: 2.11 Âµs (t3.xlarge)
- **ğŸ“¦ JSON Marshaling**: 26.80 Âµs (t3.xlarge)

---

## ğŸ¯ Next Steps

Ready to implement Bifrost in your architecture? Choose your deployment path:

| **Deployment**            | **Documentation**                                         | **Time Investment** |
| ------------------------- | --------------------------------------------------------- | ------------------- |
| **ğŸ”§ Go Package**         | [Go Integration Guide](../quick-start/go-package.md)      | 5 minutes           |
| **ğŸŒ HTTP Transport**     | [HTTP Deployment Guide](../quick-start/http-transport.md) | 10 minutes          |
| **ğŸ› ï¸ Production Setup**   | [Production Configuration](../configuration/)             | 30 minutes          |
| **ğŸ“Š Performance Tuning** | [Benchmarks & Optimization](../benchmarks.md)             | 20 minutes          |
| **ğŸ”Œ Custom Extensions**  | [Plugin Development](../features/plugins.md)              | 45 minutes          |

### ğŸ“– Complete Reference

- **[ğŸ—ï¸ Feature Documentation](../features/)** - All Bifrost capabilities
- **[âš™ï¸ Configuration Reference](../configuration/)** - Complete setup guides
- **[ğŸ“‹ API Documentation](../usage/)** - HTTP and Go SDK references
- **[ğŸ”§ Development Guides](../guides/)** - Tutorials and best practices

---

**ğŸš€ Ready to deploy?** Start with our [ğŸ“– Quick Start Guides](../quick-start/) to get Bifrost running in under 2 minutes.
