# ğŸš€ Quick Start Guide

Get up and running with Bifrost in under 30 seconds. Choose your preferred integration method and follow the step-by-step guides below.

## ğŸ“‹ Quick Start Options

| Method                                         | Best For                                          | Time to Setup | Documentation              |
| ---------------------------------------------- | ------------------------------------------------- | ------------- | -------------------------- |
| **[ğŸ”§ Go Package](go-package.md)**             | Go applications, custom logic, direct integration | ~30 seconds   | Direct code integration    |
| **[ğŸŒ HTTP Transport](http-transport.md)**     | Any language, microservices, existing APIs        | ~60 seconds   | REST API via Docker/binary |
| **[ğŸ”„ Drop-in Integrations](integrations.md)** | Migrating existing apps, zero-code changes        | ~15 seconds   | Replace existing endpoints |

---

## ğŸ¯ Which Option Should I Choose?

### ğŸ”§ **Go Package** - Choose if you:

- âœ… Are building a Go application
- âœ… Want direct code integration and type safety
- âœ… Need custom business logic and advanced features
- âœ… Prefer compile-time configuration validation
- âœ… Want maximum performance with minimal overhead

### ğŸŒ **HTTP Transport** - Choose if you:

- âœ… Use any programming language (Python, Node.js, etc.)
- âœ… Want to keep AI logic separate from your application
- âœ… Need a centralized AI gateway for multiple services
- âœ… Prefer REST API integration patterns
- âœ… Want to scale AI requests independently

### ğŸ”„ **Drop-in Integrations** - Choose if you:

- âœ… Have existing OpenAI/Anthropic/GenAI code
- âœ… Want zero-code migration with instant benefits
- âœ… Need immediate fallback and load balancing
- âœ… Want to test Bifrost without changing your app
- âœ… Are migrating from LiteLLM or similar gateways

---

## âš¡ 30-Second Setup

### Option 1: Go Package (Fastest)

```bash
# Install package
go get github.com/maximhq/bifrost/core

# Set API key
export OPENAI_API_KEY="your-openai-key"

# Run the example
go run main.go
```

**[â†’ Complete Go Package Guide](go-package.md)**

### Option 2: HTTP Transport (Universal)

```bash
# Start Bifrost
docker run -p 8080:8080 -e OPENAI_API_KEY maximhq/bifrost

# Test with curl
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"provider":"openai","model":"gpt-4o-mini","messages":[{"role":"user","content":"Hello!"}]}'
```

**[â†’ Complete HTTP Transport Guide](http-transport.md)**

### Option 3: Drop-in Integration (Zero Code Changes)

```bash
# Start Bifrost with OpenAI compatibility
docker run -p 8080:8080 -e OPENAI_API_KEY maximhq/bifrost

# Replace OpenAI endpoint in your existing code
# Before: https://api.openai.com/v1/chat/completions
# After:  http://localhost:8080/openai/v1/chat/completions
```

**[â†’ Complete Integration Guide](integrations.md)**

---

## ğŸ†š Feature Comparison

Confused about which method offers what features? Check our comprehensive feature matrix:

**[â†’ Feature Comparison Table](feature-comparison.md)**

---

## ğŸš€ What's Next?

After completing the quick start:

1. **[ğŸ”§ Configuration](../configuration/README.md)** - Customize Bifrost for your needs
2. **[ğŸ¯ Features](../features/README.md)** - Explore advanced capabilities
3. **[ğŸ“š API Reference](../usage/README.md)** - Complete API documentation
4. **[ğŸ“– Guides](../guides/README.md)** - Detailed tutorials and examples

---

## ğŸ’¡ Need Help?

- **[ğŸ” Troubleshooting](../guides/troubleshooting.md)** - Common issues and solutions
- **[â“ FAQ](../guides/faq.md)** - Frequently asked questions
- **[ğŸ¤ Contributing](../contributing/README.md)** - Get involved in development

---

**âš¡ Ready to get started? Pick your preferred method above and follow the guide!**
